# SKP

## 概要

`skp` 全称为 `simulate kernel programming` 即模拟（防）内核（Linux）编程，主要是借鉴内核的接口、算法以及风格等。

现移植和改造了以下的主要的接口和算法：

1. 原子、位图与引用计数
2. 数据结构 ：双向链表、哈希链表、哈希表、红黑树
2. 互斥 ：自旋锁、读写锁、位图锁、互斥量、读写信号量
3. 同步：等待队列、完成变量
4. 线程 ：工作队列、定时器
5. 工具 ：断言（动态和静态）、GCC扩展封装、哈希函数等
6. 对内核用于协议操作的 `skb` 进行重新设计，实现了名为 `pbuff` 的协议缓存对象
7. 内存分配器，基于伙伴系统和 `slub` 算法的改造实现。

另仿照内核代码的设计风格实现了：

1. 套接字辅助函数
2. `reactor` IO事件模型
3. 基于事件模型实现的网络IO库 ———— `xprt` 传输对象
4. 单向链表、字典表（可自动伸缩的哈希表）、向量（可自动扩展的数组）、整数 `ID` 分配器
5. 简单日志
6. 递归互斥量


如果需要组合该库中各个组件，都应该以一种面向对象的方式来使用，数据结构的封装以 `侵入式` 的组合，而非对对象指针的引用，比如：

```
struct base_class;
struct class_ops {
	/*create*/
	struct base_class *init(void *);
	/*destroy*/
	void finit(struct base_class*);
	/*other action*/
};
struct base_class {
	char name [32];
	spinlock_t lock;
	struct dict attr;
	/*operator set*/
	const struct class_ops *ops;
};
struct sub_class {
	time_t birthday;
	struct base_class base;
};

static struct base_class _init(struct class_ops *ops, void *data)
{
	struct sub_class *sub = malloc(*sub);
	assert(ops && ops->init == _init);

	sub->base.ops = ops;
	/*initial other fields with data*/
	return &sub->base;
}

static void _finit(struct base_class *_base)
{
	struct sub_class *sub;
	sub = container_of(_base, struct sub, base);
	/*release other fields*/
	free(sub);
}

static struct class_ops __sub_ops = {
	.init = _init,
	.finit = _finit,
};

struct base_class *create_sub_class(void *data)
{
	return __sub_ops._init(&__sub_ops, data);
}

void destroy_sub_class(struct base_class *base)
{
	if (!base)
		return;
	base->ops->_finit(base);
}
```

**聚集操纵函数不一定是必须的，但是 `内嵌` 应该是必须的，在实现本库的时候也大量的使用了这种设计。该编码风格在 `linux` 内核中大量存在，不仅是可维护性，更可以提供更好的性能。因为操纵的数据在物理上都是相邻的，提高了 `CPU` 缓存线的命中，从而提高了访存速度。**

## 原子操作

为了能在操作系统全局将算数运算、位运算、先判断再运算或先运算再判断等非单个机器指令的操作不被其他路径打断，从而破坏被操纵数据的一致性，CPU提供 `lock;` 前缀来组合一些可原子组合的指令，这些统称为 `原子操作`。

原子的算数运算可以保证数据的单调性，比如即使不使用复杂的锁，多个操作者也能通过一个操作在任意时刻就可以递增或递减一个数，这些是基本的原子操作。更多的时候我们需要在操作数据前，先判断一个条件，当条件成立才执行算数或位运算，并且能返回真假值来指示是否执行过运算，比如如果一个数大于0才执行减一的操作，或如果一个数已经等于某个值则不进行加减操作。

这部分实现不仅提供原子的操作API，也以同样的原语对部分操作提供非原子的API，其目的是为了让在框架设计上一定可以互斥的操作能通过非原子的运算提供更好的性能，因为*原子操作也是有CPU资源代价*的。

## 位图操作

位图可以看做由很多拨动开关组成的数据结构，通过API可以很好的操纵其中的任何一个或多个开关。位图是一个位的集合，既然是集合就提供集合的一些常见的运算，比如交集、差集、合集等。位图由机器字节的数组成，所以在局部也可以使用原子操作的API。

位图是非常有用且高效的，比如我们将某些业务用整数表示，再将客户对这些业务的权限抽象成一个或多个位图并设置应当拥有的位（业务），那么我们可以很方便的计算出哪些客户有办理了相同或不同的业务，在某个时刻系统能处理或不能处理的业务也使用位图表示，那么我们还可以做到快速的对办理业务的客户进行过滤。

**简单来说一切又多个状态组成的事物都可以为其抽象一个位图**。配合原子操作，该套API是状态机设计和操作的最佳伙伴。

## 双向链表

双向链表是一种线性的，可以在其任意一个点或方向操纵的数据结构。可以将它比作铁路系统，每个站点就是链表的节点，具有方向性的两条铁轨连接着某两个站点，通过“铁轨”我们可以来回找寻链表中的“站点” ———— 节点。它的使用非常简单，实现也高效的，非常复杂的操作也不过5、6个赋值操作。

链表节点是连接其他对象的“纽带”的抽象，必须以一种嵌入式的方式才能发挥其原有的性能，比如，设计一个连接所有 `人` 这个对象的所需的数据结构：

```
struct list_head {
	struct list_head *next;
	struct list_head *prev;
} person_list = { &person_list, &person_list, };

struct person {
	char name[32];
	struct list_head node;
};
/*create a person object*/
struct person *zhangsan = New_Person("zhangsan");
/*add a person to list*/
list_add(&zhangsan->node, &person_list);
/*del a person from list*/
list_del(&zhangsan->node);

Del_Person(zhangsan);
```

非常自然的语义，将张三加入到链表中，又将张三从链表中删除，“节点”是张三的一部分，可以将其看做人的手，与生俱来的事物，我们要组成一个队伍 ———— 链表，那么只需要手牵手就可以了。这就是上面提及的 `侵入式` 的编程方式，所有容器类都应该必须使用这样的方式，保证数据在物理上的紧凑性、相邻性，效率才能提高。

传统的容器，包括C++是 `STL` 库（非 `boost` 提供侵入式容器）都是非侵入式的，这样虽然可以将API做到非常好的重用性、一致性，但却在操作容器中的元素时需要二次物理上非相邻的寻址，当数据量过大而CPU的高速缓存一定时，会出现非常多的缓存失效，严重影响性能。就上面的例子一会是这样设计的：

```
struct list_node {
	struct list_node *next;
	struct list_node *prev;
	void *data;
};

struct list_head {
	struct list_node *head;
	struct list_node *tail;
} person_list = { NULL, NULL, };

struct person {
	char name[32];
};

struct person *zhangsan = New_Person("zhangsan");
struct list_node *zhangsan_node = New_Node(zhangsan);

list_add(zhangsan_node, &person_list);
list_del(zhangsan_node);

Del_Node(zhangsan_node);
Del_Person(zhangsan);

```

简单来说我们为了将人组成队伍，多创造了一个“纽带” ———— 节点，这个动作实实在在的发生了，我们多分配一次内存。在队伍解散时也是一样，还需要销毁“纽带” ———— 多释放一次内存。无论效率和安全性都打了折扣。

链表的操作主要包括，在任意位置插入节点、删除处于任意位置的节点、合并两个链表、移动节点等。这部分实现还升级了传统链表的遍历，创造了多种实用性很高的遍历链表辅助宏，他们以高级语言（包括非编译性语言）惯用的 `list_for_each_xxx` 作为作为前缀，保证了易读性。

```
merge one list to other

              prev       +------+        next
              +----\\----| list |----\\-----+
              |          +------+           |
              V                             V
           +----+    +----+    +----+    +----+
    new+-->|    |<==>|    |<==>|    |<==>|    |<--+new
       |   +----+    +----+    +----+    +----+   |
       v                                          v
    +------+                                  +------+
    | head |<============\......\============>| next |
    +------+                                  +------+
	   ^                                          |
       |   +----+    +----+    +----+    +----+   |
    old+---|    |<==>|    |<==>|    |<==>|    |<--+old
           +----+    +----+    +----+    +----+

```

## 单向链表

与双向链表相似，不同的是只能从两端增减数据，并且只能向一个方向遍历内嵌的元素。该数据结构同样应该使用 `侵入式`

```
single list have tow pointer, they point the head and tail of list

           +----+    +----+    +----+    +----+
           |    |--->|    |--->|    |--->|    |---> nullpointer
           +----+    +----+    +----+    +----+
             ^                              ^
             |                              |
         +------+                       +------+
         | head |                       | tail |
         +------+                       +------+

```

## 哈希链表

与双向链表很相似，也有两个方向，但是它向前的方向不是为了反向遍历，而是为了 `O(1)` 的删除节点，该链表主要用于组成静态大小的哈希表。实现时提供了很多辅助函数来快速的创建静态的哈希表，或内嵌、或全局、或局部，并提供全表遍历或单个哈希桶的遍历，并且声明的哈希表的大小一定是 `2^x` 指数大小的，这样可以通过单指令的位运算就可以通过哈希值计算出键处于哪个哈希桶中。

```
hash list is a special list, they are often used to compose hash tables.

     hash table
    +---------+     hlist
    | +-----+ |    +-----+    +-----+    +-----+    +-----+    +-----+
    | |first|+|--->| k/v |<-->| k/v |<-->| k/v |<-->| k/v |<-->| k/v |-> nullpointer
    | +-----+ |    +-----+    +-----+    +-----+    +-----+    +-----+
    |         |
    | +-----+ |    +-----+    +-----+    +-----+
    | |first|+|--->| k/v |<-->| k/v |<-->| k/v |-> nullpointer
    | +-----+ |    +-----+    +-----+    +-----+
    |         |
    | +-----+ |    +-----+    +-----+    +-----+    +-----+
    | |first|+|--->| k/v |<-->| k/v |<-->| k/v |<-->| k/v |-> nullpointer
    | +-----+ |    +-----+    +-----+    +-----+    +-----+
    |         |
    | +-----+ |    +-----+    +-----+
    | |first|+|--->| k/v |<-->| k/v |->nullpointer
    | +-----+ |    +-----+    +-----+
    +---------+

```

## 红黑树

红黑树也是一颗二叉树，即对于每个非叶子节点都一个或两个子节点，叶子节点没有任何子节点。红黑树在插入和删除其中的节点时，通过旋转来保证任何一个节点的左右两遍的高度大致相同，从而使二分查找时，左右两侧的路径长度基本一致。为了完成这个需求，需要对每个节点进行作色标记，分红色和黑色，故称为红黑树。

红黑树是非线性结构的，在其中查找有很大的性能提升，但是如果需要遍历红黑树，需要在路径上做一次回溯，所以这回比线性的链表遍历慢。通常如果一个特殊的数据结构即需要高效的查找，又需要高效的遍历，就同时需要将节点即嵌入到链表节点，又嵌入到红黑树节点，每次插入、删除操作都让两种基础数据结构联动。查找时使用树，遍历时使用链表。这种用法在 `Linux` 内核管理进程的虚地址空间上有应用。

红黑树通过比较被管理元素的值进行排序（逻辑上有序），根据比较规则可以定义为升序或降序。按正数升序排列的红黑树可以充当 `最小堆` 的实现，这是实现高效的定时器的关键组件。

```

                    +----+
                    |node|
                    +----+
                   /      \
             +----+        +----+
             |node|        |node|
             +----+        +----+
            /      \             \
      +----+        +----+        +----+
      |node|        |node|        |node|
      +----+        +----+        +----+

```

## 自旋锁

锁是保证多个不能组成原子运算或操作的一致性的重要组件，这些操作的集合叫做临界区。一般可以将软件中的锁比作现实中锁，该锁只有一把钥匙，没有其他备用的钥匙，所以在同一时刻只可能有一个人，且是同一个人能打开或关闭锁。可以将锁的操作做下面的假说，某一个人进入房间时，用挂在锁上的钥匙打开锁，拔掉钥匙进门并将门反锁，其他人想进门就只能等屋里的人开关门并用锁上后，将钥匙挂在锁上才能进入。

操作系统一般会运行多个进程，每个进程按一定长度的时间片来共享使用CPU资源，即每个进程运行一会，然后内核强制要其让出CPU资源，并选择另一个合适的进程让其使用CPU资源，这个过程非常的快，一般为1到20毫秒，如此循环给计算机使用者一种多个应用程序在“同时运行”的错觉。程序在无事可做或运行条件为达到的时候，一般会主动让出CPU的资源。

自选锁的是一个特殊锁，在使用该锁的时候，程序要求操作系统一直调度自己，然后自己去查看锁是否就绪。而不是尝试获取锁失败的时候，要求持有锁的进程在释放锁的时候通知自己，然后自己挂起、休眠等待这个通知。很忙明显第二种方式更能提高CPU的利用率，CPU不必将等待某个未成立条件的进程唤醒，而是专注执行程序的正常业务。任何事物都是具有两面性的，第二种方式带来了较高的延迟，即使条件成了并发出了唤醒信号，休眠进程还是被迫等待该自己运行时候才会执行，这与内核调度算法有关，简单来的说，进程休眠的经常会被视为不活跃的进程，减低调度频率，从而增加了缓存未命中。

通过上面的阐述，可以假设一种较为特殊的情况出现，多个程序竞争锁来操纵一个临界区，而这个临界区的耗时刚好不会超过最小调度时间片，那么A先被调度运行，当A获取锁开始操作临界区，然后操作系统调度B，B试图获取锁但不会成功，然后主动或被动让出CPU，当不要求自己休眠，A又被调度，当其运行到被再次调度出去后，已经离开了临界区并释放了锁，B恰好到了运行的时机，他立马就可以获取到锁并继续操作临界区。 **总的来说，所被保护的临界区的执行耗时不超过最小时间片，就可以使用自旋锁来提高效率**。

基本的自旋锁的实现简单，只需要原子的抢占设置位操作即可，仅有两种状态，*已加锁*或*未加锁*，使用自旋锁时，流程如下：

1. 加锁成功
2. 操作临界区
3. 解锁

```
timing sequence about schedule of A and B

         lock     +-> size of tick
          |      /         unlock
          |     /           |
  [A] S---o-------S.....S---o-------S.............
          |<---Critical --->|
  [B]  ...........S--o--s...........S--o-------o-S
                    /                  |        \
      trylock fail +                  lock       + unlock

`S` : passive schedule
's' : active schedule

```

## 读写锁

读写锁基于自旋锁实现，几乎所有的同步工具都使用自旋锁来作为基础组件。它和自旋锁无论在接口或使用准则上非常相似，除了：

1. 有3种状态，写加锁、读加锁、未加锁，读写互斥。
2. 为写加锁，只能有一个进程能修改临界区的数据。
3. 为读加锁，可以有多个进程能读取临界区的数据。

## 位图锁

自旋锁的变种，与自旋锁有相同的语义（加锁和解锁）。可以使用一个位将需要修改的数据直接作为锁，而不需要另外内存来构造一把锁，通常在需要大量的锁而又想节约内存开销时存在。在模拟多路信号灯时也可以直接使用位图锁，只有多个位同时加锁后，才执行某项任务。

## 互斥量

互斥量也是基于自旋锁实现的，与自旋锁有相同的语义（加锁和解锁），但在内部实现上有差异。所有加锁失败的进程都通过系统调用将自己放入一个内核级别等待队列，然后挂起休眠直到持有锁的进程解锁后，如果发现有等待锁的进程存在，则从内核态唤醒这个进程，这个就是上面自旋锁描述的非轮询查看条件是否成立的过程。互斥量适合只有允许一个进程长时间操作临界区的场景。

## 读写信号量

读写信号量也是自旋锁实现的，但它的语义与读写锁相同，在内部实现上有与互斥量相同，即加锁失败后，在操作系统的基本上休眠等待唤醒。

看上去上面所介绍的各种互斥原语在 或在`posix` 或在 `pthread` 线程库中都有实现，但是自己重造一次轮子，是为了更好的实现非常特殊的线程池，后续才介绍。

## 等待队列

等待队列是用于进程或线程同步的，可以方便查看一个条件是否成立，不成立就休眠等待，直到条件成立。为了防止系统级别的惊群效应，我们在用户态设置一个队列，选择性的唤醒一些等待条件的线程。为了防止低概率条件能被准确的捕捉，即不会出现一旦错过触发时机线程就一直休眠下去，导致应用假死。其原语和使用规则可以描述为（移除锁的干扰）：

1. 将当前线程加入一个队列，必须要先加入队列，否则可能错误唤醒时机，导致永远休眠下去。
2. 判断条件是否成立，如果条件不成立则挂起进程（可以使用超时机制），直到由其他线程将条件设置为真后唤醒本线程，然后再判断条件。
3. 条件成立从队列中移除本线程。

一般的 `posix` 的条件变量 `pthread_cond_t` 必须配合 `pthread_mutex_t` 互斥量一起使用包临界区，而 互斥量 是一种专为长临界区设计的锁，对应原子或其他耗时低于 1ms 的条件的判断，这无疑是很大程度的降低了性能。这里设计的等待队列 直接使用 `futex` 系统调用作为底层实现，上层可以根据临界区的长度自由的选择适当的锁，以提高性能。而且如果条件是原子的，可以直接使用 `futex` 的封装，极大的提高了进程或线程间同步的性能。

`futex` 是 Linux 系统提供的使用内核的的等待队列的系统调用，全称叫做 `fast user mutex` 快速用户互斥量，这样也是 `posix` 线程库的各种同步原件的实现基石。在 `macos` 系统中是没有这个系统调用的，由于暂时没有找到 `macos` 的原生同步系统调用，所以 `macos` 平台的 `futex` 的封装暂时使用了 `posix` 的条件变量和互斥量。

## 完成变量

完成变量是等待队列的封装，其语义就是将条件看做一种可以增减的资源 —————— 用数字表示，有点像多值信号量，只要资源可用 ———— 数值大于0则递减数值，然后返回，否则等待数值大于0。

这在线程同步时非常有用和快捷，比如 面试中，考官常常会除一道类似 让多个线程按顺序先后的执行多少秒钟。如果使用完成变量来做控制，只需要每个线程绑定一个完成变量，保证其他某个线程可以访问这个变量，每个线程先等待自己的完成变量就绪，就绪后执行指定的秒数，然后增加下一个需要执行的线程（所有线程执行顺序假设是环形的）的完成变量的值，最后又回到第一步等待自己的完成变量就绪，线程环境创建好之后，只需要在主线程唤醒任意一个线程，就可以达到顺序执行的目的了。

该库中完成变量会在线程的启动和停止时，用于等待启动和停止信号。

## 定时器

定时器用于定时的完成一些任务，由于定时器一定与一个函数绑定，所以也可以将定时器视为 `延迟函数` ———— 延迟一段时候再运行这个函数。

定时器由定时器对象和定时器队列组成，定时器对象的使用是被作为一个 `基类` 来使用的 ———— `侵入式` 编程，抽象的定时器对象并不会包含一个指针，用于与其他的对象绑定，使用时一定是嵌入到其他关联这个定时器的上下文的对象之中，回调函数只需要将定时器 `基类` 指针传入即可，然后使用 指针运算 （一般是 `container_of()` ）获得真正的上下文对象指针，如：

```
struct timer {
    ...
    void (*timer_cb)(struct timer*);
};

struct ctx_obj {
    struct timer timer;
    /*other context field*/
    ...
};

static void delay_func(struct timer *__timer)
{
    struct ctx_obj *ctx = container_of(__timer, struct ctx_obj, timer);
    /*do some work*/
    ...
}

static void timer_init(struct timer *timer, void (*timer_cb)(struct timer*))
{
    timer->timer_cb = timer_cb;
}

int main(void)
{
    struct ctx_obj ctx;

    timer_init(&ctx.timer, delay_func);

    /*startup timer*/
    ...
}

```

不仅是 `定时器对象` ，后续介绍的 `事件对象` 、 `工作对象` 都是以这样的方式运作，以后就不再一一赘述了。

定时器的内部数据结构使用了红黑树来模拟小堆，其无论启动、停止还是获取当前最小定时值，其性能都非常良好，该定时器的特性如下：

1. 定时器的回调函数的运行上下文是共有的，不是每一个定时器都为其创造运行上下文 ———— **共享**线程。
2. 有一组数量一定的全局线程作为定时器上下文（一般为CPU数量，在编译时给出），每个线程都是绑定CPU的，以更好的利用高速缓存。因为定时器本来就是一个延迟函数，不需要精准对待，这样做API就简单明了，不必在传递一个指定的上下文局部，而且定时器上下文与其他事件运行上下文分离，可以通过进程优先级来优化调度，比如降低定时器线程的优先级，让其他事件优先运行。
3. 因为运行上下文进行了CPU绑定，所以可以将定时器的运行上下文分派到指定CPU上运行，在不指定的情况下，定时器是均匀的被分派到所有CPU上执行。
4. 启动定时器时间复杂度为 `O(lgn)`，如果定时器已启动，可以更新定时器，时间复杂度与启动一样。
5. 停止定时器时间复杂度为 `O(1)`，停止定时器有同步与异步的分别，同步停止表示如果定时器已经在调用回调函数，那么必须等待回调完成；异步表示只确保删除已排队的定时器，不关心其回调函数是否在运行。

在定时器之上还有一个 `rcu_call` 的语义 ———— 在每个CPU上的服务于定时器的线程都经历一小段时间后，才回调一个特定的函数，其主要为后续实现数据结构的 `rcu`方位 ———— 即读拷贝修改，在已读方式访问数据结构时，不需要加锁，比如遍历链表。

由于定时器对象中含有红黑树节点对象，而仅红黑树的每个节点就需要3个机器字大小，总的内存量需要7个机器字，对于64位操作系统就是 56 个字节，还是比较占用内存的，所以在设计延迟行为时需要适当的计算内存的消耗。

## 工作队列

工作队列就是线程池，工作就是需要执行的任务回调函数。其核心思想还是共享运行上下文 ———— 线程，将其与任务的私有属性分离，可以做到固定线程数，但是可以有多样的线程池。

工作队列在对外的API上由工作对象和工作队列两部分组成，工作对象的特性与定时器对象一致，它是联系任务上下文的纽带。但工作队列在设计上除了有系统预设的一组默认工作队列对象以外，还允许创建特有的属性的工作队列对象。

工作队列的实现较为复杂，其特性描述如下：

1. 预设一组工作队列对象，每个工作队列关联底层的特定的线程组，这些线程组被属性相同的工作队列共享。
2. 在线程组中的工作线程的数量可以伸缩，当向其中排队时，如果需要则创建一些新的线程加入到组中，并设置一个定时器，当这些线程很久都没有服务任何工作对象时，就从组中移除并销毁他们 ———— **主动创建和回收工作线程**。
3. 预设的工作队列分为两类，一种绑定线程的工作队列，对应绑定线程组，在普通情况下其中的排队的任务的并发度为一，即只有一个任务在运行；另一种是非绑定的工作队列，并发度可以配置。
4. 可以主动创建特定的工作线程，由于底层是共享工作线程的，所以不必担心线程太多导致上下文切换的开销过大。
5. 既然已经绑定了线程，就没必要创建太多，仅需要每个CPU上创建唯一的线程组就够了，所以全框架只要有绑定属性的工作队列在特定的CPU上都是共享同一组线程组。但为了体现任务的优先性，绑定的线程组又分为普通优先级的线程和高优先级的线程，这可以利用内核调度来优化任务的优先级。
6. 非绑定的工作队列使用哈希来共享一组全局的非绑定线程组，使用哈希函数计算出线程组数组的下标，然后共享其中的线程组，没有分CPU的概念。
7. 多级排队工作对象，先排队到关联的线程组的队列中，当此数量达到某一个阈值时，就排队到工作队列本身，等待已排队的任务完成之后，发现关联的工作队列中有延迟的任务，则取出一个继续执行。因为工作对象的执行属性由工作队列决定，所以这样的多节排队可以实现控制某一类任务的并发度，当并发度为一时，则工作队列就变成特殊的顺序任务队列了。
8. 工作对象的排队也一样可以指定排队到某个某个特定的CPU上，但必须要求指定的工作队列是绑定属性，否则会被忽略。不指定CPU则内部采用轮转的方式进行均匀分配。
9. 工作对象的取消排队与定时器的删除一样，有同步和异步之分。
10. 提供一个特殊的接口，可以等待工作对象完成。
11. **如果工作对象被执行过一次，那么下次排队将继续在那个线程上运行，提高了缓存线的命中率**。
12. **如果工作回调中出现锁的挂起等待（自旋类的锁不会，锁必须是以上自己设计的），则会自动唤醒所在线程组中的其他线程自动的取下一个任务来执行**。这个功能提供的接口是可以自主调用的，这样当在完成一个非常承重的任务，比如有大量的系统调用参与，但是我们又被排队到了绑定线程组中，就可以主动的调用一次，以临时的改变并发度。由于有这个需求，所以才会重新实现一遍锁类接口。

## 辅助函数

辅助函数是对一些常用运算、断言等进行封装，比较重要的如下：

1. 静态与动态断言
2. 静态分支预测
3. 判断变量类型是否相等、是否为数组
4. 计算、判断对齐
5. 以2为底的幂运算
6. 自旋查看变量
7. 伪随机函数
8. 近似（单调）时间戳获取、运算
9. 全局递归大锁
10. 线程绑定、线程号获取、进程号获取

## 协议缓存

根据内核 `skb` 对象改造的，主要用于操作协议栈的数据结构，它包含描述句柄和数据块这两部分。主要实现以下的功能：

1. 自动扩展数据块的内存。
2. 以栈或队列的方式操作数据块。
3. 深拷贝和浅拷贝（拷贝之后共享数据块）

```
one data block be shared by tow pbuffs

    [pbuff A]
     +--------------------------+
     | head | data | tail | end |
     +-+-------+-------+-----+--+
      /        |        \     \______________________
     |         |         \                           \
     v---------v----------v---------------------------v----+
     |         |//////////|  [DATA]    |\\\\\\\\\|    |refs|
     ^---------------------------------^---------^----^----+
      \___________________________      \        |    \___
                                  \      \       |        \
                                +--+------+------+---------+
                                | head | data | tail | end |
                                +--------------------------+
                               [pbuff B]
```

缓存对象带有多个回调函数，大都在所涉及的操作需要分配内存的时候就会触发，因为分配内存后需要更新原对象中的指针，否则原对象中存储的指针会变为野指针，该缓存对象的用法是完全参照面向对象来设计的，包括构造、析构、赋值、拷贝等回调函数，如果不设置则不会调用，比如将缓存对象当动态数组使用时。

这套API接口可以做很多事，虽然它本质上是数组操作，但是在用于操纵协议解析与构造时，使用上是有规律可循的，有了这套接口可以大大的精简和美化代码。

下面将使用一个例子来说明在网络协议解析时，怎样使用这个缓存对象，为了方面说明，其中指针仅是一个逻辑上有效的值。先假设协议是一个最简单的消息长度加消息负载，还是使用 `浸入式` 编程，为了描述使用缓存对象和一般传统模式之间的本质，并假设所有的单个包数据都是一次性到达，即不会出现只收到一部分包头或包体，如果是这样就还需要状态机辅助才能正确解析。

先介绍传统的一般方式：

```
struct PkgHead {
    size_t length;
};

struct Pkg {
    struct PkgHead head;
    char body[0];
};
```

1. 预估协议数据的大小，分配一个超过一般包长度的 `Pkg` 对象。
2. 读取包头，一次系统调用。
3. 根据包头长度查看是否需要扩展 `Pkg` 的长度，如果需要则又多一次数据拷贝。
4. 最后读取包体长度，一次系统调用。
5. 处理完毕后，释放内存。
6. 继续第一步的操作，循环直到收到结束分节。

```
/*消息头*/
struct PkgHead {
    size_t length;
};

/*解析器，作为缓存对象的继承类，包括已解释的头指针和以填充的协议数据的缓存对象*/
struct Parser {
    struct PkgHead *head;
    char *body;
    struct pbuff buff;
    struct pbuff *upper; /*上半部以解析的数据*/
    struct work_struct work; /*工作对象*/
};

```

1. 首先使用预定义 `buff` 构造函数来构造一个至少能包含数个一般长度的 `Parser` 对象，因为从未接收过数据，所以 `upper` 字段为空，这正存储数据的块隐藏在 `pbuff` 对象中。
2. 已缓存中剩余空间来接收数据，该次接收可以做到一次系统调用就接收数个的完整包（或加一个非完整包）的效果。
3. 开始解析数据，包头解析完毕后将指针存储在 `head` 中，它指向 `buff` 中的实际数据块；再将后接的包体指针存储在 `body` 中，此时已经消费了一个完整的包数据了，`buff` 中的起始数据是下一个包体的。在这个解析过程中，没有任何数据的拷贝，仅仅是指针移动。
4. 如果还有为解析数据，则使用预定义在 `buff` 中的回调函数浅拷贝 `Parser`，仅仅是 `Parser` 这个描述符的拷贝，并重置 `head` 和 `body` 字段，因为数据还没有解析，整个过程的数据量非常小，可以忽略。新生产的 `Parser` 对象与已解析完毕的对象共享填充协议数据的内存块。
5. 将已解析的 `Parser` 对象通过工作队列扔给其他线程并行的处理，然后使用新的 `Parser` 对象继续第三步的解析工作。
6. 如果没有数据可以解析或者解析到非完整的包，那么继续第一步，构造一个全新的 `Parser` 对象，如果有未解析完毕的数据则将当前操作的 `Parser` 对象存储在 `upper` 字段中，否则释放对象，由于共享的数据块有引用计数的管理，所以即使这个对象是浅拷贝而来的，也不用担心将共享的数据错误的释放掉。
7. 继续第二步操作，并重复以上所有的过程，直到接收到结束分节。

从上面的对比可以得出 使用封装的 缓存对象 来操作协议可以更少的系统调用和更少的数据拷贝，在线程间传递也非常安全。

